{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"9c6da53ade2302c5c2549050a755f7271f56c4989f0bdbb18e4ce6e64f091b09"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames[:3]:\n#         print(os.path.join(dirname, filename))\n#     if len(filenames) > 3:\n#         print(\"...\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-12-13T04:31:52.418719Z","iopub.execute_input":"2022-12-13T04:31:52.419212Z","iopub.status.idle":"2022-12-13T04:31:52.445813Z","shell.execute_reply.started":"2022-12-13T04:31:52.419102Z","shell.execute_reply":"2022-12-13T04:31:52.444798Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import csv\nimport cv2\nimport numpy as np\nimport random\nimport os\nimport time\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision.io import read_image\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:31:52.449874Z","iopub.execute_input":"2022-12-13T04:31:52.452398Z","iopub.status.idle":"2022-12-13T04:31:54.549957Z","shell.execute_reply.started":"2022-12-13T04:31:52.452358Z","shell.execute_reply":"2022-12-13T04:31:54.548902Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"/kaggle/input/captcha-hacker/train\"\nTEST_PATH = \"/kaggle/input/captcha-hacker/test\"\n#TRAIN_PATH = \"./train\"\n#TEST_PATH = \"./test\"\ndevice = torch.device(\"cuda\")\n# try device = \"cuda\" \n# and change your settings/accelerator to GPU if you want it to run faster","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:31:54.551693Z","iopub.execute_input":"2022-12-13T04:31:54.552570Z","iopub.status.idle":"2022-12-13T04:31:54.558415Z","shell.execute_reply.started":"2022-12-13T04:31:54.552532Z","shell.execute_reply":"2022-12-13T04:31:54.557797Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"code = {}\nrev_code = {}\n\nnum = 0\nfor i in range(10):\n    code[str(i)] = num\n    rev_code[num] = str(i)\n    num += 1\n\nfor i in range(ord('a'), ord('z') + 1):\n    code[chr(i)]  = num\n    rev_code[num] = chr(i)\n    num += 1\n\n#print(code)   \n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:31:54.561381Z","iopub.execute_input":"2022-12-13T04:31:54.562963Z","iopub.status.idle":"2022-12-13T04:31:54.571055Z","shell.execute_reply.started":"2022-12-13T04:31:54.562926Z","shell.execute_reply":"2022-12-13T04:31:54.569881Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def calc_acc(output, label):  \n    digits = int(output.shape[1] / 36)\n    output, label = output.view((-1, digits , 36)), label.view((-1, digits, 36))\n    output = nn.functional.softmax(output, dim=2)\n    #print(output.shape)\n    #print(label.shape)\n    output, label = torch.argmax(output, dim=2), torch.argmax(label, dim=2)\n    #print(label)\n    #print(output)\n    correct = torch.sum(output == label, dim=1)\n    #print(correct)\n    correct = torch.sum(correct == digits, dim=0)\n\n    return correct","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:31:54.575201Z","iopub.execute_input":"2022-12-13T04:31:54.576251Z","iopub.status.idle":"2022-12-13T04:31:54.583587Z","shell.execute_reply.started":"2022-12-13T04:31:54.576212Z","shell.execute_reply":"2022-12-13T04:31:54.582590Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data = []\nval_data = []\n\nwith open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n    for row in csv.reader(csvfile, delimiter=','):\n        if random.random() < 0.8:\n            train_data.append(row)\n        else:\n            val_data.append(row)\n\ntest_data = []\nwith open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n    for row in csv.reader(csvfile, delimiter=','):\n        test_data.append(row)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:31:54.585335Z","iopub.execute_input":"2022-12-13T04:31:54.586095Z","iopub.status.idle":"2022-12-13T04:31:54.646956Z","shell.execute_reply.started":"2022-12-13T04:31:54.586060Z","shell.execute_reply":"2022-12-13T04:31:54.645815Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## TASK1","metadata":{}},{"cell_type":"code","source":"class Task1Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        #img = cv2.resize(img, (32, 32))\n        #img = np.mean(img, axis=2)\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            return img, int(label)\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:31:54.651534Z","iopub.execute_input":"2022-12-13T04:31:54.652313Z","iopub.status.idle":"2022-12-13T04:31:54.665982Z","shell.execute_reply.started":"2022-12-13T04:31:54.652272Z","shell.execute_reply":"2022-12-13T04:31:54.664805Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_ds = Task1Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task1Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:31:54.670411Z","iopub.execute_input":"2022-12-13T04:31:54.670803Z","iopub.status.idle":"2022-12-13T04:31:54.683001Z","shell.execute_reply.started":"2022-12-13T04:31:54.670769Z","shell.execute_reply":"2022-12-13T04:31:54.681760Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"task1_model = resnet18(pretrained=True)\ntask1_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\ntask1_mode = task1_model.to(device)\n#print(model)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:31:54.687929Z","iopub.execute_input":"2022-12-13T04:31:54.688282Z","iopub.status.idle":"2022-12-13T04:32:06.380765Z","shell.execute_reply.started":"2022-12-13T04:31:54.688248Z","shell.execute_reply":"2022-12-13T04:32:06.379804Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5cff295b5643d9980314b44a4db4f3"}},"metadata":{}}]},{"cell_type":"code","source":"#model = Model().to(device)\noptimizer = torch.optim.Adam(task1_model.parameters(), lr=1e-3)\nloss_fn = nn.CrossEntropyLoss()\n\n\nfor epoch in range(15):\n    print(f\"Epoch [{epoch}]\")\n    task1_model.train()\n    for image, label in train_dl:\n        image = image.to(device)\n        label = label.to(device)\n        \n        pred = task1_model(image)\n        loss = loss_fn(pred, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        torch.cuda.empty_cache()\n        \n    sample_count = 0\n    correct_count = 0\n    task1_model.eval()\n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n\n            pred = task1_model(image)\n            loss = loss_fn(pred, label)\n\n            pred = torch.argmax(pred, dim=1)\n\n            sample_count += len(image)\n            correct_count += (label == pred).sum()\n\n            del image, label, pred\n            torch.cuda.empty_cache()\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:32:06.384898Z","iopub.execute_input":"2022-12-13T04:32:06.385193Z","iopub.status.idle":"2022-12-13T04:34:12.296134Z","shell.execute_reply.started":"2022-12-13T04:32:06.385166Z","shell.execute_reply":"2022-12-13T04:34:12.294856Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch [0]\naccuracy (validation): tensor(0.9483, device='cuda:0')\nEpoch [1]\naccuracy (validation): tensor(0.9767, device='cuda:0')\nEpoch [2]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [3]\naccuracy (validation): tensor(0.9922, device='cuda:0')\nEpoch [4]\naccuracy (validation): tensor(0.9948, device='cuda:0')\nEpoch [5]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [6]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [7]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [8]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [9]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [10]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [11]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [12]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [13]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [14]\naccuracy (validation): tensor(1., device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n\n\n\"\"\" if os.path.exists('submission.csv'):\n    csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\nelse:\n\"\"\"\nif os.path.exists('submission.csv'):\n    os.remove('submission.csv')\n    \nfile = open('submission.csv', 'w', newline='')\ncsv_writer = csv.writer(file)\ncsv_writer.writerow([\"filename\", \"label\"])\n\n\ntask1_model.eval()\nwith torch.no_grad():\n    for image, filenames in test_dl:\n        image = image.to(device)\n\n        pred = task1_model(image)\n        pred = torch.argmax(pred, dim=1)\n\n        for i in range(len(filenames)):\n            csv_writer.writerow([filenames[i], str(pred[i].item())])\n\n        del image, pred\n        torch.cuda.empty_cache()\n    \nfile.close()\n\ndel task1_model, train_ds, train_dl, val_ds, val_dl, test_ds, test_dl\ntorch.cuda.empty_cache()\ntime.sleep(10)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:34:12.298258Z","iopub.execute_input":"2022-12-13T04:34:12.298934Z","iopub.status.idle":"2022-12-13T04:35:30.321400Z","shell.execute_reply.started":"2022-12-13T04:34:12.298895Z","shell.execute_reply":"2022-12-13T04:35:30.320007Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## TASK2","metadata":{}},{"cell_type":"code","source":"class Task2Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        #img = cv2.resize(img, (32, 32))\n        #img = np.mean(img, axis=2)\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            #new_label = np.array([code[label[0]], code[label[1]]])\n            #new_label = [0] * 72\n            new_label = np.zeros(shape=72)\n            new_label[code[label[0]]] = 1\n            new_label[code[label[1]]+36] = 1\n            #new_label += np.array([0, 36])\n            new_label = torch.LongTensor(new_label)\n            return img, new_label\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:35:30.323127Z","iopub.execute_input":"2022-12-13T04:35:30.323827Z","iopub.status.idle":"2022-12-13T04:35:30.334874Z","shell.execute_reply.started":"2022-12-13T04:35:30.323790Z","shell.execute_reply":"2022-12-13T04:35:30.332882Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_ds = Task2Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task2Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:35:30.336377Z","iopub.execute_input":"2022-12-13T04:35:30.337458Z","iopub.status.idle":"2022-12-13T04:35:30.347901Z","shell.execute_reply.started":"2022-12-13T04:35:30.337422Z","shell.execute_reply":"2022-12-13T04:35:30.346985Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Task2Model(nn.Module):\n    def __init__(self):\n        super(Task2Model, self).__init__()\n\n        self.resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n        self.fc1 = nn.Linear(in_features=1000, out_features=36, bias=True)\n        self.fc2 = nn.Linear(in_features=1000, out_features=36, bias=True)\n\n    def forward(self, x):\n        x = self.resnet(x)\n        output_1 = self.fc1(x)\n        output_2 = self.fc2(x)\n\n        return output_1, output_2\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:35:30.349503Z","iopub.execute_input":"2022-12-13T04:35:30.349900Z","iopub.status.idle":"2022-12-13T04:35:30.357932Z","shell.execute_reply.started":"2022-12-13T04:35:30.349866Z","shell.execute_reply":"2022-12-13T04:35:30.356913Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"task2_model = resnet18(pretrained=True)\ntask2_model.fc = nn.Linear(in_features=512, out_features=72, bias=True)\ntask2_model = task2_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:35:30.359386Z","iopub.execute_input":"2022-12-13T04:35:30.360059Z","iopub.status.idle":"2022-12-13T04:35:30.581510Z","shell.execute_reply.started":"2022-12-13T04:35:30.359975Z","shell.execute_reply":"2022-12-13T04:35:30.580438Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#task2_model = Task2Model().to(device)\n#weights = ResNet18_Weights.IMAGENET1K_V1\n#preprocess = weights.transforms()\n\n#task2_model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n#task2_model = densenet201(weights=DenseNet201_Weights.IMAGENET1K_V1)\n#task2_model.fc = nn.Linear(in_features=512, out_features=72, bias=True)\n\noptimizer = torch.optim.Adam(task2_model.parameters(), lr=1e-3)\n#loss_fn = nn.CrossEntropyLoss()\nloss_fn = nn.MultiLabelSoftMarginLoss()\n\n\nfor epoch in range(15):\n    print(f\"Epoch [{epoch}]\")\n    task2_model.train()\n\n    train_loss = 0.0\n    for image, label in train_dl:\n\n        image = image.to(device)\n        #label_1, label_2 = label[:, 0], label[:, 1]\n        label = label.to(device)\n        #label_1, label_2 = label_1.to(device, dtype=torch.long), label_2.to(device, dtype=torch.long)\n        \n        #pred_1, pred_2 = task2_model(image)\n        #image_transformed = preprocess(image)\n\n        pred = task2_model(image)\n        loss = loss_fn(pred, label)\n        #loss_1, loss_2 = loss_fn(pred_1, label_1), loss_fn(pred_2, label_2)\n        \n        #loss = loss_1 + loss_2\n        train_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        torch.cuda.empty_cache()\n    \n    #print(len(train_dl))\n    train_loss /= len(train_dl)\n    print(\"train loss: {}\".format(train_loss))\n\n    sample_count = 0\n    correct_count = 0\n    task2_model.eval()\n    val_loss = 0\n    \n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n            #label_1, label_2 = label[:, 0], label[:, 1]\n            #label_1, label_2 = label_1.to(device, dtype=torch.long), label_2.to(device, dtype=torch.long)\n\n            #pred_1, pred_2 = task2_model(image)\n            #loss_1, loss_2 = loss_fn(pred_1, label_1), loss_fn(pred_2, label_2)\n\n            #loss = loss_1 + loss_2\n            #val_loss += loss\n            #print(\"loss: {}\".format(loss))\n\n            #image_transformed = preprocess(image)\n\n            pred = task2_model(image)\n            loss = loss_fn(pred, label)\n            #print(\"pred: \", pred)\n            #print(\"label: \", label)\n            val_loss += loss\n            #pred_1, pred_2 = torch.argmax(pred_1, dim=1), torch.argmax(pred_2, dim=1)\n            #pred = torch.stack([pred_1, pred_2], dim=1)\n\n            sample_count += len(image)\n            #correct = torch.sum(pred == label, dim=1)\n            #print(correct)\n            correct_count += calc_acc(pred, label)\n            #correct_count += torch.sum(correct == 2)\n\n            del image, label, pred\n            torch.cuda.empty_cache()\n\n        val_loss /= len(val_dl)\n        print(\"val loss: {}\".format(val_loss))\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:35:30.583265Z","iopub.execute_input":"2022-12-13T04:35:30.583902Z","iopub.status.idle":"2022-12-13T04:37:52.460674Z","shell.execute_reply.started":"2022-12-13T04:35:30.583861Z","shell.execute_reply":"2022-12-13T04:37:52.458672Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch [0]\ntrain loss: 0.1962503045797348\nval loss: 0.17250965535640717\naccuracy (validation): tensor(0.0119, device='cuda:0')\nEpoch [1]\ntrain loss: 0.06740159541368484\nval loss: 0.04786376655101776\naccuracy (validation): tensor(0.6950, device='cuda:0')\nEpoch [2]\ntrain loss: 0.028290068730711937\nval loss: 0.02163233608007431\naccuracy (validation): tensor(0.9446, device='cuda:0')\nEpoch [3]\ntrain loss: 0.013269573450088501\nval loss: 0.013592088595032692\naccuracy (validation): tensor(0.9564, device='cuda:0')\nEpoch [4]\ntrain loss: 0.007797346916049719\nval loss: 0.010911944322288036\naccuracy (validation): tensor(0.9743, device='cuda:0')\nEpoch [5]\ntrain loss: 0.005378466099500656\nval loss: 0.007089290302246809\naccuracy (validation): tensor(0.9921, device='cuda:0')\nEpoch [6]\ntrain loss: 0.004010448697954416\nval loss: 0.007270704489201307\naccuracy (validation): tensor(0.9782, device='cuda:0')\nEpoch [7]\ntrain loss: 0.0032453290186822414\nval loss: 0.004959181882441044\naccuracy (validation): tensor(0.9941, device='cuda:0')\nEpoch [8]\ntrain loss: 0.0027239981573075056\nval loss: 0.004161291290074587\naccuracy (validation): tensor(0.9941, device='cuda:0')\nEpoch [9]\ntrain loss: 0.0023166562896221876\nval loss: 0.0037792385555803776\naccuracy (validation): tensor(0.9941, device='cuda:0')\nEpoch [10]\ntrain loss: 0.002015758538618684\nval loss: 0.0033923364244401455\naccuracy (validation): tensor(0.9901, device='cuda:0')\nEpoch [11]\ntrain loss: 0.0017304171342402697\nval loss: 0.003138011321425438\naccuracy (validation): tensor(0.9921, device='cuda:0')\nEpoch [12]\ntrain loss: 0.0014852286549285054\nval loss: 0.0025545309763401747\naccuracy (validation): tensor(0.9960, device='cuda:0')\nEpoch [13]\ntrain loss: 0.0013536845799535513\nval loss: 0.0025158924981951714\naccuracy (validation): tensor(0.9921, device='cuda:0')\nEpoch [14]\ntrain loss: 0.0012194582959637046\nval loss: 0.0021527118515223265\naccuracy (validation): tensor(0.9960, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = Task2Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n\nfile = open('submission.csv', 'a', newline='')\ncsv_writer = csv.writer(file)\n\ntask2_model.eval()\nwith torch.no_grad():\n    for image, filenames in test_dl:\n        image = image.to(device)\n\n        pred = task2_model(image)\n        pred = pred.view(-1, 2, 36)\n        pred = torch.argmax(pred, dim=2)\n\n        for i in range(len(filenames)):\n            csv_writer.writerow([filenames[i], rev_code[pred[i][0].item()] + rev_code[pred[i][1].item()]])\n\n        del image, pred\n        torch.cuda.empty_cache()\n    \nfile.close()\ndel task2_model, train_ds, train_dl, val_ds, val_dl, test_ds, test_dl\ntorch.cuda.empty_cache()\ntime.sleep(10)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:37:52.463984Z","iopub.execute_input":"2022-12-13T04:37:52.464854Z","iopub.status.idle":"2022-12-13T04:38:28.637845Z","shell.execute_reply.started":"2022-12-13T04:37:52.464794Z","shell.execute_reply":"2022-12-13T04:38:28.636760Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## TASK3","metadata":{}},{"cell_type":"code","source":"class Task3Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        #img = cv2.resize(img, (32, 32))\n        #img = np.mean(img, axis=2)\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            new_label = np.zeros(shape=144)\n            for i in range(4):\n                new_label[code[label[i]]+i*36] = 1\n            new_label = torch.LongTensor(new_label)\n            return img, new_label\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:38:28.639135Z","iopub.execute_input":"2022-12-13T04:38:28.639441Z","iopub.status.idle":"2022-12-13T04:38:28.649610Z","shell.execute_reply.started":"2022-12-13T04:38:28.639414Z","shell.execute_reply":"2022-12-13T04:38:28.648603Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_ds = Task3Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task3Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:38:28.651187Z","iopub.execute_input":"2022-12-13T04:38:28.652027Z","iopub.status.idle":"2022-12-13T04:38:28.660650Z","shell.execute_reply.started":"2022-12-13T04:38:28.651992Z","shell.execute_reply":"2022-12-13T04:38:28.659706Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class Task3Model(nn.Module):\n    def __init__(self):\n        super(Task3Model, self).__init__()\n\n        self.resnet = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n        self.fc1 = nn.Linear(in_features=1000, out_features=36, bias=True)\n        self.fc2 = nn.Linear(in_features=1000, out_features=36, bias=True)\n        self.fc3 = nn.Linear(in_features=1000, out_features=36, bias=True)\n        self.fc4 = nn.Linear(in_features=1000, out_features=36, bias=True)\n\n    def forward(self, x):\n        x = self.resnet(x)\n        output_1 = self.fc1(x)\n        output_2 = self.fc2(x)\n        output_3 = self.fc3(x)\n        output_4 = self.fc4(x)\n\n        return output_1, output_2, output_3, output_4","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:38:28.662189Z","iopub.execute_input":"2022-12-13T04:38:28.662558Z","iopub.status.idle":"2022-12-13T04:38:28.672878Z","shell.execute_reply.started":"2022-12-13T04:38:28.662524Z","shell.execute_reply":"2022-12-13T04:38:28.671955Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"task3_model = resnet18(pretrained=True)\ntask3_model.fc = nn.Linear(in_features=512, out_features=144, bias=True)\ntask3_model = task3_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:38:28.674529Z","iopub.execute_input":"2022-12-13T04:38:28.675097Z","iopub.status.idle":"2022-12-13T04:38:28.893512Z","shell.execute_reply.started":"2022-12-13T04:38:28.674928Z","shell.execute_reply":"2022-12-13T04:38:28.892551Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#task3_model = Task3Model().to(device)\n\noptimizer = torch.optim.Adam(task3_model.parameters(), lr=1e-3)\nloss_fn = nn.MultiLabelSoftMarginLoss()\n#loss_fn = nn.CrossEntropyLoss()\n\n\nfor epoch in range(30):\n    print(f\"Epoch [{epoch}]\")\n    task3_model.train()\n\n    train_loss = 0.0\n    for image, label in train_dl:\n\n        image = image.to(device)\n        #label_1, label_2 = label[:, 0], label[:, 1]\n        label = label.to(device)\n        #label_1, label_2 = label_1.to(device, dtype=torch.long), label_2.to(device, dtype=torch.long)\n        \n        #pred_1, pred_2 = task2_model(image)\n        #image_transformed = preprocess(image)\n\n        pred = task3_model(image)\n        loss = loss_fn(pred, label)\n        #loss_1, loss_2 = loss_fn(pred_1, label_1), loss_fn(pred_2, label_2)\n        \n        #loss = loss_1 + loss_2\n        train_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        torch.cuda.empty_cache()\n    \n    #print(len(train_dl))\n    train_loss /= len(train_dl)\n    print(\"train loss: {}\".format(train_loss))\n\n    sample_count = 0\n    correct_count = 0\n    task3_model.eval()\n    val_loss = 0\n    \n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n            #label_1, label_2 = label[:, 0], label[:, 1]\n            #label_1, label_2 = label_1.to(device, dtype=torch.long), label_2.to(device, dtype=torch.long)\n\n            #pred_1, pred_2 = task2_model(image)\n            #loss_1, loss_2 = loss_fn(pred_1, label_1), loss_fn(pred_2, label_2)\n\n            #loss = loss_1 + loss_2\n            #val_loss += loss\n            #print(\"loss: {}\".format(loss))\n\n            #image_transformed = preprocess(image)\n\n            pred = task3_model(image)\n            loss = loss_fn(pred, label)\n            #print(\"pred: \", pred)\n            #print(\"label: \", label)\n            val_loss += loss\n            #pred_1, pred_2 = torch.argmax(pred_1, dim=1), torch.argmax(pred_2, dim=1)\n            #pred = torch.stack([pred_1, pred_2], dim=1)\n\n            sample_count += len(image)\n            #correct = torch.sum(pred == label, dim=1)\n            #print(correct)\n            correct_count += calc_acc(pred, label)\n            #correct_count += torch.sum(correct == 2)\n\n            del image, label, pred\n            torch.cuda.empty_cache()\n\n        val_loss /= len(val_dl)\n        print(\"val loss: {}\".format(val_loss))\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:38:28.894920Z","iopub.execute_input":"2022-12-13T04:38:28.895293Z","iopub.status.idle":"2022-12-13T04:45:48.461607Z","shell.execute_reply.started":"2022-12-13T04:38:28.895259Z","shell.execute_reply":"2022-12-13T04:45:48.460320Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch [0]\ntrain loss: 0.1917160600423813\nval loss: 0.14850692451000214\naccuracy (validation): tensor(0., device='cuda:0')\nEpoch [1]\ntrain loss: 0.1174943670630455\nval loss: 0.115991972386837\naccuracy (validation): tensor(0., device='cuda:0')\nEpoch [2]\ntrain loss: 0.09696988761425018\nval loss: 0.08866866677999496\naccuracy (validation): tensor(0.0053, device='cuda:0')\nEpoch [3]\ntrain loss: 0.06995102763175964\nval loss: 0.061455752700567245\naccuracy (validation): tensor(0.1373, device='cuda:0')\nEpoch [4]\ntrain loss: 0.0475832037627697\nval loss: 0.048766396939754486\naccuracy (validation): tensor(0.3468, device='cuda:0')\nEpoch [5]\ntrain loss: 0.031772732734680176\nval loss: 0.033385686576366425\naccuracy (validation): tensor(0.8011, device='cuda:0')\nEpoch [6]\ntrain loss: 0.021780159324407578\nval loss: 0.025534093379974365\naccuracy (validation): tensor(0.8697, device='cuda:0')\nEpoch [7]\ntrain loss: 0.015332452952861786\nval loss: 0.01945440284907818\naccuracy (validation): tensor(0.9419, device='cuda:0')\nEpoch [8]\ntrain loss: 0.01122820284217596\nval loss: 0.015986917540431023\naccuracy (validation): tensor(0.9472, device='cuda:0')\nEpoch [9]\ntrain loss: 0.008692998439073563\nval loss: 0.01357522513717413\naccuracy (validation): tensor(0.9525, device='cuda:0')\nEpoch [10]\ntrain loss: 0.006859461776912212\nval loss: 0.01168869249522686\naccuracy (validation): tensor(0.9613, device='cuda:0')\nEpoch [11]\ntrain loss: 0.005573924630880356\nval loss: 0.009866560809314251\naccuracy (validation): tensor(0.9595, device='cuda:0')\nEpoch [12]\ntrain loss: 0.004547985270619392\nval loss: 0.008668934926390648\naccuracy (validation): tensor(0.9648, device='cuda:0')\nEpoch [13]\ntrain loss: 0.00383566040545702\nval loss: 0.008262612856924534\naccuracy (validation): tensor(0.9630, device='cuda:0')\nEpoch [14]\ntrain loss: 0.0033501610159873962\nval loss: 0.007631171029061079\naccuracy (validation): tensor(0.9648, device='cuda:0')\nEpoch [15]\ntrain loss: 0.0029105430003255606\nval loss: 0.007035808637738228\naccuracy (validation): tensor(0.9736, device='cuda:0')\nEpoch [16]\ntrain loss: 0.0024946010671555996\nval loss: 0.0063187917694449425\naccuracy (validation): tensor(0.9736, device='cuda:0')\nEpoch [17]\ntrain loss: 0.0021892189979553223\nval loss: 0.00590316578745842\naccuracy (validation): tensor(0.9718, device='cuda:0')\nEpoch [18]\ntrain loss: 0.0019573336467146873\nval loss: 0.005522930063307285\naccuracy (validation): tensor(0.9771, device='cuda:0')\nEpoch [19]\ntrain loss: 0.0017509134486317635\nval loss: 0.005224212072789669\naccuracy (validation): tensor(0.9789, device='cuda:0')\nEpoch [20]\ntrain loss: 0.0015792542835697532\nval loss: 0.005003414116799831\naccuracy (validation): tensor(0.9718, device='cuda:0')\nEpoch [21]\ntrain loss: 0.0014196012634783983\nval loss: 0.004656188189983368\naccuracy (validation): tensor(0.9683, device='cuda:0')\nEpoch [22]\ntrain loss: 0.0012962865876033902\nval loss: 0.004266034811735153\naccuracy (validation): tensor(0.9806, device='cuda:0')\nEpoch [23]\ntrain loss: 0.001159818610176444\nval loss: 0.00412604259327054\naccuracy (validation): tensor(0.9789, device='cuda:0')\nEpoch [24]\ntrain loss: 0.0010645401198416948\nval loss: 0.003908609040081501\naccuracy (validation): tensor(0.9771, device='cuda:0')\nEpoch [25]\ntrain loss: 0.000982031342573464\nval loss: 0.0039051873609423637\naccuracy (validation): tensor(0.9771, device='cuda:0')\nEpoch [26]\ntrain loss: 0.0009056940907612443\nval loss: 0.003682701848447323\naccuracy (validation): tensor(0.9789, device='cuda:0')\nEpoch [27]\ntrain loss: 0.0008493298082612455\nval loss: 0.003552833339199424\naccuracy (validation): tensor(0.9789, device='cuda:0')\nEpoch [28]\ntrain loss: 0.0007837996818125248\nval loss: 0.0036034747026860714\naccuracy (validation): tensor(0.9754, device='cuda:0')\nEpoch [29]\ntrain loss: 0.0007321520242840052\nval loss: 0.003349393606185913\naccuracy (validation): tensor(0.9789, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = Task3Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n\nfile = open('submission.csv', 'a', newline='')\ncsv_writer = csv.writer(file)\n\ntask3_model.eval()\n\nwith torch.no_grad():\n    for image, filenames in test_dl:\n        image = image.to(device)\n\n        pred = task3_model(image)\n        pred = pred.view(-1, 4, 36)\n        pred = torch.argmax(pred, dim=2)\n\n        for i in range(len(filenames)):\n            csv_writer.writerow([filenames[i], rev_code[pred[i][0].item()] + rev_code[pred[i][1].item()] + \\\n                                                rev_code[pred[i][2].item()] + rev_code[pred[i][3].item()]])    \n\n        del image, pred\n        torch.cuda.empty_cache()\n    \nfile.close()    \ndel task3_model, train_ds, train_dl, val_ds, val_dl, test_ds, test_dl\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:45:48.463393Z","iopub.execute_input":"2022-12-13T04:45:48.465477Z","iopub.status.idle":"2022-12-13T04:46:00.699837Z","shell.execute_reply.started":"2022-12-13T04:45:48.465436Z","shell.execute_reply":"2022-12-13T04:46:00.698825Z"},"trusted":true},"execution_count":23,"outputs":[]}]}