{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames[:3]:\n#         print(os.path.join(dirname, filename))\n#     if len(filenames) > 3:\n#         print(\"...\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-12-14T05:13:33.129035Z","iopub.execute_input":"2022-12-14T05:13:33.129600Z","iopub.status.idle":"2022-12-14T05:13:33.188992Z","shell.execute_reply.started":"2022-12-14T05:13:33.129483Z","shell.execute_reply":"2022-12-14T05:13:33.187800Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import csv\nimport numpy as np\nimport random\nimport os\nimport time\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision.io import read_image\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:13:33.191998Z","iopub.execute_input":"2022-12-14T05:13:33.197849Z","iopub.status.idle":"2022-12-14T05:13:35.595246Z","shell.execute_reply.started":"2022-12-14T05:13:33.197810Z","shell.execute_reply":"2022-12-14T05:13:35.594153Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"/kaggle/input/captcha-hacker/train\"\nTEST_PATH = \"/kaggle/input/captcha-hacker/test\"\n#TRAIN_PATH = \"./train\"\n#TEST_PATH = \"./test\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# try device = \"cuda\" \n# and change your settings/accelerator to GPU if you want it to run faster","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:13:35.599541Z","iopub.execute_input":"2022-12-14T05:13:35.600042Z","iopub.status.idle":"2022-12-14T05:13:35.672188Z","shell.execute_reply.started":"2022-12-14T05:13:35.600013Z","shell.execute_reply":"2022-12-14T05:13:35.671187Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"code = {}\nrev_code = {}\n\nnum = 0\nfor i in range(10):\n    code[str(i)] = num\n    rev_code[num] = str(i)\n    num += 1\n\nfor i in range(ord('a'), ord('z') + 1):\n    code[chr(i)]  = num\n    rev_code[num] = chr(i)\n    num += 1\n\n#print(code)   \n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:13:35.674525Z","iopub.execute_input":"2022-12-14T05:13:35.674878Z","iopub.status.idle":"2022-12-14T05:13:35.685966Z","shell.execute_reply.started":"2022-12-14T05:13:35.674850Z","shell.execute_reply":"2022-12-14T05:13:35.684880Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def calc_acc(output, label):  \n    digits = int(output.shape[1] / 36)\n    output, label = output.view((-1, digits , 36)), label.view((-1, digits, 36))\n    output = nn.functional.softmax(output, dim=2)\n    \n    output, label = torch.argmax(output, dim=2), torch.argmax(label, dim=2)\n    \n    correct = torch.sum(output == label, dim=1)\n    correct = torch.sum(correct == digits, dim=0)\n\n    return correct","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:13:35.687588Z","iopub.execute_input":"2022-12-14T05:13:35.688144Z","iopub.status.idle":"2022-12-14T05:13:35.696882Z","shell.execute_reply.started":"2022-12-14T05:13:35.688099Z","shell.execute_reply":"2022-12-14T05:13:35.695674Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data = []\nval_data = []\n\nwith open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n    for row in csv.reader(csvfile, delimiter=','):\n        if random.random() < 0.85:\n            train_data.append(row)\n        else:\n            val_data.append(row)\n\ntest_data = []\nwith open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n    for row in csv.reader(csvfile, delimiter=','):\n        test_data.append(row)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:13:35.698444Z","iopub.execute_input":"2022-12-14T05:13:35.698814Z","iopub.status.idle":"2022-12-14T05:13:35.751417Z","shell.execute_reply.started":"2022-12-14T05:13:35.698778Z","shell.execute_reply":"2022-12-14T05:13:35.750457Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## TASK1","metadata":{}},{"cell_type":"code","source":"class Task1Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        \n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            return img, int(label)\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:13:35.752892Z","iopub.execute_input":"2022-12-14T05:13:35.753575Z","iopub.status.idle":"2022-12-14T05:13:35.764003Z","shell.execute_reply.started":"2022-12-14T05:13:35.753536Z","shell.execute_reply":"2022-12-14T05:13:35.762968Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_ds = Task1Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task1Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:13:35.765668Z","iopub.execute_input":"2022-12-14T05:13:35.766393Z","iopub.status.idle":"2022-12-14T05:13:35.776110Z","shell.execute_reply.started":"2022-12-14T05:13:35.766355Z","shell.execute_reply":"2022-12-14T05:13:35.775172Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"task1_model = resnet18(pretrained=True)\ntask1_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\ntask1_mode = task1_model.to(device)\n#print(model)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:13:35.777579Z","iopub.execute_input":"2022-12-14T05:13:35.778652Z","iopub.status.idle":"2022-12-14T05:13:40.889646Z","shell.execute_reply.started":"2022-12-14T05:13:35.778561Z","shell.execute_reply":"2022-12-14T05:13:40.888651Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f178c7d6cf7c4625995417214f43ac03"}},"metadata":{}}]},{"cell_type":"code","source":"\noptimizer = torch.optim.Adam(task1_model.parameters(), lr=3e-4)\nloss_fn = nn.CrossEntropyLoss()\n\n\nfor epoch in range(15):\n    print(f\"Epoch [{epoch}]\")\n    task1_model.train()\n    for image, label in train_dl:\n        image = image.to(device)\n        label = label.to(device)\n        \n        pred = task1_model(image)\n        loss = loss_fn(pred, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        #torch.cuda.empty_cache()\n        \n    sample_count = 0\n    correct_count = 0\n    task1_model.eval()\n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n\n            pred = task1_model(image)\n            loss = loss_fn(pred, label)\n\n            pred = torch.argmax(pred, dim=1)\n\n            sample_count += len(image)\n            correct_count += (label == pred).sum()\n\n            del image, label, pred\n            #torch.cuda.empty_cache()\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:13:40.893585Z","iopub.execute_input":"2022-12-14T05:13:40.894150Z","iopub.status.idle":"2022-12-14T05:15:28.332104Z","shell.execute_reply.started":"2022-12-14T05:13:40.894104Z","shell.execute_reply":"2022-12-14T05:15:28.330906Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch [0]\naccuracy (validation): tensor(0.9579, device='cuda:0')\nEpoch [1]\naccuracy (validation): tensor(0.9965, device='cuda:0')\nEpoch [2]\naccuracy (validation): tensor(0.9930, device='cuda:0')\nEpoch [3]\naccuracy (validation): tensor(0.9965, device='cuda:0')\nEpoch [4]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [5]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [6]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [7]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [8]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [9]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [10]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [11]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [12]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [13]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [14]\naccuracy (validation): tensor(1., device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n\n\nif os.path.exists('submission.csv'):\n    os.remove('submission.csv')\n    \nfile = open('submission.csv', 'w', newline='')\ncsv_writer = csv.writer(file)\ncsv_writer.writerow([\"filename\", \"label\"])\n\n\ntask1_model.eval()\nwith torch.no_grad():\n    for image, filenames in test_dl:\n        image = image.to(device)\n\n        pred = task1_model(image)\n        pred = torch.argmax(pred, dim=1)\n\n        for i in range(len(filenames)):\n            csv_writer.writerow([filenames[i], str(pred[i].item())])\n\n        del image, pred\n        #torch.cuda.empty_cache()\n    \nfile.close()\n\ndel task1_model, train_ds, train_dl, val_ds, val_dl, test_ds, test_dl\n#torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:15:28.336799Z","iopub.execute_input":"2022-12-14T05:15:28.339224Z","iopub.status.idle":"2022-12-14T05:16:10.926199Z","shell.execute_reply.started":"2022-12-14T05:15:28.339181Z","shell.execute_reply":"2022-12-14T05:16:10.925128Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## TASK2","metadata":{}},{"cell_type":"code","source":"class Task2Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        \n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            #new_label = np.array([code[label[0]], code[label[1]]])\n            #new_label = [0] * 72\n            new_label = np.zeros(shape=72)\n            new_label[code[label[0]]] = 1\n            new_label[code[label[1]]+36] = 1\n            #new_label += np.array([0, 36])\n            new_label = torch.LongTensor(new_label)\n            return img, new_label\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:16:10.931108Z","iopub.execute_input":"2022-12-14T05:16:10.933428Z","iopub.status.idle":"2022-12-14T05:16:10.946644Z","shell.execute_reply.started":"2022-12-14T05:16:10.933389Z","shell.execute_reply":"2022-12-14T05:16:10.945796Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_ds = Task2Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task2Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:16:10.951456Z","iopub.execute_input":"2022-12-14T05:16:10.954385Z","iopub.status.idle":"2022-12-14T05:16:10.965098Z","shell.execute_reply.started":"2022-12-14T05:16:10.954349Z","shell.execute_reply":"2022-12-14T05:16:10.963985Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"task2_model = resnet18(pretrained=True)\ntask2_model.fc = nn.Linear(in_features=512, out_features=72, bias=True)\ntask2_model = task2_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:16:10.969836Z","iopub.execute_input":"2022-12-14T05:16:10.972477Z","iopub.status.idle":"2022-12-14T05:16:11.347044Z","shell.execute_reply.started":"2022-12-14T05:16:10.972442Z","shell.execute_reply":"2022-12-14T05:16:11.345949Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(task2_model.parameters(), lr=1e-3)\nloss_fn = nn.MultiLabelSoftMarginLoss()\n\n\nfor epoch in range(15):\n    print(f\"Epoch [{epoch}]\")\n    task2_model.train()\n\n    train_loss = 0.0\n    for image, label in train_dl:\n\n        image = image.to(device)\n        label = label.to(device)\n\n        pred = task2_model(image)\n        loss = loss_fn(pred, label)\n        \n        train_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        #torch.cuda.empty_cache()\n    \n    train_loss /= len(train_dl)\n    print(\"train loss: {}\".format(train_loss))\n\n    sample_count = 0\n    correct_count = 0\n    task2_model.eval()\n    val_loss = 0\n    \n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n\n            pred = task2_model(image)\n            loss = loss_fn(pred, label)\n            val_loss += loss\n\n            sample_count += len(image)\n            correct_count += calc_acc(pred, label)\n\n            del image, label, pred\n            #torch.cuda.empty_cache()\n\n        val_loss /= len(val_dl)\n        print(\"val loss: {}\".format(val_loss))\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:16:11.352378Z","iopub.execute_input":"2022-12-14T05:16:11.355046Z","iopub.status.idle":"2022-12-14T05:18:20.350049Z","shell.execute_reply.started":"2022-12-14T05:16:11.355002Z","shell.execute_reply":"2022-12-14T05:18:20.348742Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch [0]\ntrain loss: 0.18274368345737457\nval loss: 0.10016883909702301\naccuracy (validation): tensor(0.0633, device='cuda:0')\nEpoch [1]\ntrain loss: 0.05587545037269592\nval loss: 0.03314933553338051\naccuracy (validation): tensor(0.8785, device='cuda:0')\nEpoch [2]\ntrain loss: 0.02165263704955578\nval loss: 0.014896048232913017\naccuracy (validation): tensor(0.9899, device='cuda:0')\nEpoch [3]\ntrain loss: 0.01013439055532217\nval loss: 0.010475752875208855\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [4]\ntrain loss: 0.0060200137086212635\nval loss: 0.0075912862084805965\naccuracy (validation): tensor(0.9924, device='cuda:0')\nEpoch [5]\ntrain loss: 0.004235154017806053\nval loss: 0.005529866088181734\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [6]\ntrain loss: 0.003306781407445669\nval loss: 0.004398234188556671\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [7]\ntrain loss: 0.0026243438478559256\nval loss: 0.0033796520438045263\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [8]\ntrain loss: 0.0021956469863653183\nval loss: 0.0032030262518674135\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [9]\ntrain loss: 0.0018752629403024912\nval loss: 0.0026194194797426462\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [10]\ntrain loss: 0.0016549316933378577\nval loss: 0.0023367288522422314\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [11]\ntrain loss: 0.0014255535788834095\nval loss: 0.002087237313389778\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [12]\ntrain loss: 0.0012611831771209836\nval loss: 0.0020105119328945875\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [13]\ntrain loss: 0.001106429030187428\nval loss: 0.0017314152792096138\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [14]\ntrain loss: 0.0010137823410332203\nval loss: 0.0014966215239837766\naccuracy (validation): tensor(1., device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = Task2Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n\nfile = open('submission.csv', 'a', newline='')\ncsv_writer = csv.writer(file)\n\ntask2_model.eval()\nwith torch.no_grad():\n    for image, filenames in test_dl:\n        image = image.to(device)\n\n        pred = task2_model(image)\n        pred = pred.view(-1, 2, 36)\n        pred = torch.argmax(pred, dim=2)\n\n        for i in range(len(filenames)):\n            csv_writer.writerow([filenames[i], rev_code[pred[i][0].item()] + rev_code[pred[i][1].item()]])\n\n        del image, pred\n        #torch.cuda.empty_cache()\n    \nfile.close()\ndel task2_model, train_ds, train_dl, val_ds, val_dl, test_ds, test_dl\n#torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:18:20.352154Z","iopub.execute_input":"2022-12-14T05:18:20.352846Z","iopub.status.idle":"2022-12-14T05:18:41.149670Z","shell.execute_reply.started":"2022-12-14T05:18:20.352798Z","shell.execute_reply":"2022-12-14T05:18:41.148511Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## TASK3","metadata":{}},{"cell_type":"code","source":"class Task3Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        \n        transform = transforms.Compose([\n            transforms.Resize(size=(384, 288)),\n            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            new_label = np.zeros(shape=144)\n            for i in range(4):\n                new_label[code[label[i]]+i*36] = 1\n            new_label = torch.LongTensor(new_label)\n            return img, new_label\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:18:41.150979Z","iopub.execute_input":"2022-12-14T05:18:41.151349Z","iopub.status.idle":"2022-12-14T05:18:41.160859Z","shell.execute_reply.started":"2022-12-14T05:18:41.151311Z","shell.execute_reply":"2022-12-14T05:18:41.159904Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_ds = Task3Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task3Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:18:41.162267Z","iopub.execute_input":"2022-12-14T05:18:41.162860Z","iopub.status.idle":"2022-12-14T05:18:41.172883Z","shell.execute_reply.started":"2022-12-14T05:18:41.162818Z","shell.execute_reply":"2022-12-14T05:18:41.171926Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"task3_model = resnet18(pretrained=True)\ntask3_model.fc = nn.Linear(in_features=512, out_features=144, bias=True)\ntask3_model = task3_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:18:41.174274Z","iopub.execute_input":"2022-12-14T05:18:41.174667Z","iopub.status.idle":"2022-12-14T05:18:41.397481Z","shell.execute_reply.started":"2022-12-14T05:18:41.174628Z","shell.execute_reply":"2022-12-14T05:18:41.396526Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(task3_model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.85)\nloss_fn = nn.MultiLabelSoftMarginLoss()\n\n\nfor epoch in range(60):\n    print(f\"Epoch [{epoch}]\")\n    task3_model.train()\n\n    train_loss = 0.0\n    for image, label in train_dl:\n\n        image = image.to(device)\n        label = label.to(device)\n\n        pred = task3_model(image)\n        loss = loss_fn(pred, label)\n        \n        train_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        #torch.cuda.empty_cache()\n    \n    scheduler.step()\n    train_loss /= len(train_dl)\n    print(\"train loss: {}\".format(train_loss))\n\n    sample_count = 0\n    correct_count = 0\n    task3_model.eval()\n    val_loss = 0\n    \n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n\n            pred = task3_model(image)\n            loss = loss_fn(pred, label)\n            val_loss += loss\n\n            sample_count += len(image)\n            correct_count += calc_acc(pred, label)\n\n            del image, label, pred\n            #torch.cuda.empty_cache()\n\n        val_loss /= len(val_dl)\n        print(\"val loss: {}\".format(val_loss))\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:18:41.398757Z","iopub.execute_input":"2022-12-14T05:18:41.399132Z","iopub.status.idle":"2022-12-14T05:36:43.982315Z","shell.execute_reply.started":"2022-12-14T05:18:41.399074Z","shell.execute_reply":"2022-12-14T05:36:43.980659Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch [0]\ntrain loss: 0.1895756721496582\nval loss: 0.14157240092754364\naccuracy (validation): tensor(0., device='cuda:0')\nEpoch [1]\ntrain loss: 0.11926259845495224\nval loss: 0.12123551219701767\naccuracy (validation): tensor(0., device='cuda:0')\nEpoch [2]\ntrain loss: 0.10905693471431732\nval loss: 0.10948117822408676\naccuracy (validation): tensor(0., device='cuda:0')\nEpoch [3]\ntrain loss: 0.09335485100746155\nval loss: 0.09041427075862885\naccuracy (validation): tensor(0.0070, device='cuda:0')\nEpoch [4]\ntrain loss: 0.07484155148267746\nval loss: 0.07298141717910767\naccuracy (validation): tensor(0.1186, device='cuda:0')\nEpoch [5]\ntrain loss: 0.05584103614091873\nval loss: 0.055208683013916016\naccuracy (validation): tensor(0.3977, device='cuda:0')\nEpoch [6]\ntrain loss: 0.03962191194295883\nval loss: 0.045006733387708664\naccuracy (validation): tensor(0.5605, device='cuda:0')\nEpoch [7]\ntrain loss: 0.02711937390267849\nval loss: 0.03173908218741417\naccuracy (validation): tensor(0.8140, device='cuda:0')\nEpoch [8]\ntrain loss: 0.01902853511273861\nval loss: 0.02774963155388832\naccuracy (validation): tensor(0.8186, device='cuda:0')\nEpoch [9]\ntrain loss: 0.014107284136116505\nval loss: 0.021105892956256866\naccuracy (validation): tensor(0.8930, device='cuda:0')\nEpoch [10]\ntrain loss: 0.01052082609385252\nval loss: 0.01732528768479824\naccuracy (validation): tensor(0.9279, device='cuda:0')\nEpoch [11]\ntrain loss: 0.008045872673392296\nval loss: 0.015689706429839134\naccuracy (validation): tensor(0.9442, device='cuda:0')\nEpoch [12]\ntrain loss: 0.006305397488176823\nval loss: 0.0136833805590868\naccuracy (validation): tensor(0.9395, device='cuda:0')\nEpoch [13]\ntrain loss: 0.005215113051235676\nval loss: 0.012378054670989513\naccuracy (validation): tensor(0.9419, device='cuda:0')\nEpoch [14]\ntrain loss: 0.0043157003819942474\nval loss: 0.010709714144468307\naccuracy (validation): tensor(0.9581, device='cuda:0')\nEpoch [15]\ntrain loss: 0.003630508668720722\nval loss: 0.010084293782711029\naccuracy (validation): tensor(0.9488, device='cuda:0')\nEpoch [16]\ntrain loss: 0.003105130512267351\nval loss: 0.008714794181287289\naccuracy (validation): tensor(0.9698, device='cuda:0')\nEpoch [17]\ntrain loss: 0.002563835121691227\nval loss: 0.008018260821700096\naccuracy (validation): tensor(0.9651, device='cuda:0')\nEpoch [18]\ntrain loss: 0.0022352654486894608\nval loss: 0.007570914924144745\naccuracy (validation): tensor(0.9674, device='cuda:0')\nEpoch [19]\ntrain loss: 0.0019813813269138336\nval loss: 0.0073567465879023075\naccuracy (validation): tensor(0.9744, device='cuda:0')\nEpoch [20]\ntrain loss: 0.0017309553222730756\nval loss: 0.006598450243473053\naccuracy (validation): tensor(0.9767, device='cuda:0')\nEpoch [21]\ntrain loss: 0.0015351545298472047\nval loss: 0.006302480585873127\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [22]\ntrain loss: 0.0013918837066739798\nval loss: 0.006046757102012634\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [23]\ntrain loss: 0.001255622017197311\nval loss: 0.005938478745520115\naccuracy (validation): tensor(0.9744, device='cuda:0')\nEpoch [24]\ntrain loss: 0.0011897051008418202\nval loss: 0.005738049745559692\naccuracy (validation): tensor(0.9837, device='cuda:0')\nEpoch [25]\ntrain loss: 0.0010791795793920755\nval loss: 0.005628776736557484\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [26]\ntrain loss: 0.0010071158176288009\nval loss: 0.005523181986063719\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [27]\ntrain loss: 0.0009439507848583162\nval loss: 0.00541438814252615\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [28]\ntrain loss: 0.0008900976972654462\nval loss: 0.005342357791960239\naccuracy (validation): tensor(0.9837, device='cuda:0')\nEpoch [29]\ntrain loss: 0.000820689951069653\nval loss: 0.0052876234985888\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [30]\ntrain loss: 0.0007643985445611179\nval loss: 0.004953642841428518\naccuracy (validation): tensor(0.9837, device='cuda:0')\nEpoch [31]\ntrain loss: 0.0007243388099595904\nval loss: 0.0050404975190758705\naccuracy (validation): tensor(0.9837, device='cuda:0')\nEpoch [32]\ntrain loss: 0.0006985529907979071\nval loss: 0.00506704393774271\naccuracy (validation): tensor(0.9721, device='cuda:0')\nEpoch [33]\ntrain loss: 0.0006586801027879119\nval loss: 0.004936157260090113\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [34]\ntrain loss: 0.0006207635742612183\nval loss: 0.0051418873481452465\naccuracy (validation): tensor(0.9744, device='cuda:0')\nEpoch [35]\ntrain loss: 0.0005892859771847725\nval loss: 0.004886932671070099\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [36]\ntrain loss: 0.0005708776880055666\nval loss: 0.004842396359890699\naccuracy (validation): tensor(0.9767, device='cuda:0')\nEpoch [37]\ntrain loss: 0.0005394766922108829\nval loss: 0.004736933391541243\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [38]\ntrain loss: 0.0005098524852655828\nval loss: 0.0045201159082353115\naccuracy (validation): tensor(0.9767, device='cuda:0')\nEpoch [39]\ntrain loss: 0.0004911606665700674\nval loss: 0.004484497010707855\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [40]\ntrain loss: 0.0004641316772904247\nval loss: 0.004391952883452177\naccuracy (validation): tensor(0.9767, device='cuda:0')\nEpoch [41]\ntrain loss: 0.0004329486982896924\nval loss: 0.004370624665170908\naccuracy (validation): tensor(0.9837, device='cuda:0')\nEpoch [42]\ntrain loss: 0.00040957643068395555\nval loss: 0.004341349005699158\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [43]\ntrain loss: 0.000400691875256598\nval loss: 0.0042526680044829845\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [44]\ntrain loss: 0.00037765936576761305\nval loss: 0.004190167877823114\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [45]\ntrain loss: 0.0003693396574817598\nval loss: 0.004251101519912481\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [46]\ntrain loss: 0.0003685282135847956\nval loss: 0.0043144975788891315\naccuracy (validation): tensor(0.9767, device='cuda:0')\nEpoch [47]\ntrain loss: 0.00034309623879380524\nval loss: 0.004267069045454264\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [48]\ntrain loss: 0.0003300048701930791\nval loss: 0.004242339171469212\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [49]\ntrain loss: 0.00031631503952667117\nval loss: 0.004160300828516483\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [50]\ntrain loss: 0.0003068673249799758\nval loss: 0.003987604286521673\naccuracy (validation): tensor(0.9837, device='cuda:0')\nEpoch [51]\ntrain loss: 0.00029925809940323234\nval loss: 0.004117780830711126\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [52]\ntrain loss: 0.00029156715027056634\nval loss: 0.004249016288667917\naccuracy (validation): tensor(0.9744, device='cuda:0')\nEpoch [53]\ntrain loss: 0.0002792843442875892\nval loss: 0.004065161105245352\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [54]\ntrain loss: 0.0002672658010851592\nval loss: 0.004040693398565054\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [55]\ntrain loss: 0.0002615520788822323\nval loss: 0.003993343561887741\naccuracy (validation): tensor(0.9837, device='cuda:0')\nEpoch [56]\ntrain loss: 0.0002499182301107794\nval loss: 0.0038879159837961197\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [57]\ntrain loss: 0.00024180706532206386\nval loss: 0.003972614649683237\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [58]\ntrain loss: 0.0002394172624917701\nval loss: 0.004020733758807182\naccuracy (validation): tensor(0.9814, device='cuda:0')\nEpoch [59]\ntrain loss: 0.00023136813251767308\nval loss: 0.003923406358808279\naccuracy (validation): tensor(0.9814, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = Task3Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n\nfile = open('submission.csv', 'a', newline='')\ncsv_writer = csv.writer(file)\n\ntask3_model.eval()\n\nwith torch.no_grad():\n    for image, filenames in test_dl:\n        image = image.to(device)\n\n        pred = task3_model(image)\n        pred = pred.view(-1, 4, 36)\n        pred = torch.argmax(pred, dim=2)\n\n        for i in range(len(filenames)):\n            csv_writer.writerow([filenames[i], rev_code[pred[i][0].item()] + rev_code[pred[i][1].item()] + \\\n                                                rev_code[pred[i][2].item()] + rev_code[pred[i][3].item()]])    \n\n        del image, pred\n        torch.cuda.empty_cache()\n    \nfile.close()    \n#del task3_model, train_ds, train_dl, val_ds, val_dl, test_ds, test_dl\n#torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-12-14T05:36:43.988629Z","iopub.execute_input":"2022-12-14T05:36:43.991563Z","iopub.status.idle":"2022-12-14T05:36:57.613327Z","shell.execute_reply.started":"2022-12-14T05:36:43.991503Z","shell.execute_reply":"2022-12-14T05:36:57.612262Z"},"trusted":true},"execution_count":21,"outputs":[]}]}