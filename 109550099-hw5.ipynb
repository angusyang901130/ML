{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"9c6da53ade2302c5c2549050a755f7271f56c4989f0bdbb18e4ce6e64f091b09"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames[:3]:\n#         print(os.path.join(dirname, filename))\n#     if len(filenames) > 3:\n#         print(\"...\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-12-13T03:48:58.818971Z","iopub.execute_input":"2022-12-13T03:48:58.819577Z","iopub.status.idle":"2022-12-13T03:48:58.848262Z","shell.execute_reply.started":"2022-12-13T03:48:58.819454Z","shell.execute_reply":"2022-12-13T03:48:58.846900Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import csv\nimport cv2\nimport numpy as np\nimport random\nimport os\nimport time\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision.io import read_image\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:48:58.850529Z","iopub.execute_input":"2022-12-13T03:48:58.851616Z","iopub.status.idle":"2022-12-13T03:49:00.923555Z","shell.execute_reply.started":"2022-12-13T03:48:58.851517Z","shell.execute_reply":"2022-12-13T03:49:00.922389Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"/kaggle/input/captcha-hacker/train\"\nTEST_PATH = \"/kaggle/input/captcha-hacker/test\"\n#TRAIN_PATH = \"./train\"\n#TEST_PATH = \"./test\"\ndevice = torch.device(\"cuda\")\n# try device = \"cuda\" \n# and change your settings/accelerator to GPU if you want it to run faster","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:49:00.925143Z","iopub.execute_input":"2022-12-13T03:49:00.925693Z","iopub.status.idle":"2022-12-13T03:49:00.931043Z","shell.execute_reply.started":"2022-12-13T03:49:00.925656Z","shell.execute_reply":"2022-12-13T03:49:00.930117Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"code = {}\nrev_code = {}\n\nnum = 0\nfor i in range(10):\n    code[str(i)] = num\n    rev_code[num] = str(i)\n    num += 1\n\nfor i in range(ord('a'), ord('z') + 1):\n    code[chr(i)]  = num\n    rev_code[num] = chr(i)\n    num += 1\n\n#print(code)   \n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:49:00.933738Z","iopub.execute_input":"2022-12-13T03:49:00.934394Z","iopub.status.idle":"2022-12-13T03:49:00.944555Z","shell.execute_reply.started":"2022-12-13T03:49:00.934344Z","shell.execute_reply":"2022-12-13T03:49:00.943629Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def calc_acc(output, label):  \n    digits = int(output.shape[1] / 36)\n    output, label = output.view((-1, digits , 36)), label.view((-1, digits, 36))\n    output = nn.functional.softmax(output, dim=2)\n    #print(output.shape)\n    #print(label.shape)\n    output, label = torch.argmax(output, dim=2), torch.argmax(label, dim=2)\n    #print(label)\n    #print(output)\n    correct = torch.sum(output == label, dim=1)\n    #print(correct)\n    correct = torch.sum(correct == digits, dim=0)\n\n    return correct","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:49:00.945974Z","iopub.execute_input":"2022-12-13T03:49:00.946704Z","iopub.status.idle":"2022-12-13T03:49:00.967081Z","shell.execute_reply.started":"2022-12-13T03:49:00.946668Z","shell.execute_reply":"2022-12-13T03:49:00.965739Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data = []\nval_data = []\n\nwith open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n    for row in csv.reader(csvfile, delimiter=','):\n        if random.random() < 0.8:\n            train_data.append(row)\n        else:\n            val_data.append(row)\n\ntest_data = []\nwith open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n    for row in csv.reader(csvfile, delimiter=','):\n        test_data.append(row)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:49:00.969298Z","iopub.execute_input":"2022-12-13T03:49:00.971578Z","iopub.status.idle":"2022-12-13T03:49:01.035964Z","shell.execute_reply.started":"2022-12-13T03:49:00.971425Z","shell.execute_reply":"2022-12-13T03:49:01.035055Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## TASK1","metadata":{}},{"cell_type":"code","source":"class Task1Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        #img = cv2.resize(img, (32, 32))\n        #img = np.mean(img, axis=2)\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            return img, int(label)\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:49:01.040028Z","iopub.execute_input":"2022-12-13T03:49:01.041214Z","iopub.status.idle":"2022-12-13T03:49:01.055440Z","shell.execute_reply.started":"2022-12-13T03:49:01.041167Z","shell.execute_reply":"2022-12-13T03:49:01.054349Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_ds = Task1Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task1Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:49:01.056889Z","iopub.execute_input":"2022-12-13T03:49:01.058513Z","iopub.status.idle":"2022-12-13T03:49:01.071377Z","shell.execute_reply.started":"2022-12-13T03:49:01.058468Z","shell.execute_reply":"2022-12-13T03:49:01.070414Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"task1_model = resnet18(pretrained=True)\ntask1_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\ntask1_mode = task1_model.to(device)\n#print(model)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:49:01.072663Z","iopub.execute_input":"2022-12-13T03:49:01.073225Z","iopub.status.idle":"2022-12-13T03:49:10.524994Z","shell.execute_reply.started":"2022-12-13T03:49:01.073192Z","shell.execute_reply":"2022-12-13T03:49:10.524004Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6984791a79034c3da38a0114fd228cc4"}},"metadata":{}}]},{"cell_type":"code","source":"#model = Model().to(device)\noptimizer = torch.optim.Adam(task1_model.parameters(), lr=1e-3)\nloss_fn = nn.CrossEntropyLoss()\n\n\nfor epoch in range(15):\n    print(f\"Epoch [{epoch}]\")\n    task1_model.train()\n    for image, label in train_dl:\n        image = image.to(device)\n        label = label.to(device)\n        \n        pred = task1_model(image)\n        loss = loss_fn(pred, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        torch.cuda.empty_cache()\n        \n    sample_count = 0\n    correct_count = 0\n    task1_model.eval()\n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n\n            pred = task1_model(image)\n            loss = loss_fn(pred, label)\n\n            pred = torch.argmax(pred, dim=1)\n\n            sample_count += len(image)\n            correct_count += (label == pred).sum()\n\n            del image, label, pred\n            torch.cuda.empty_cache()\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:49:10.529549Z","iopub.execute_input":"2022-12-13T03:49:10.529846Z","iopub.status.idle":"2022-12-13T03:51:08.432247Z","shell.execute_reply.started":"2022-12-13T03:49:10.529820Z","shell.execute_reply":"2022-12-13T03:51:08.430220Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch [0]\naccuracy (validation): tensor(0.3836, device='cuda:0')\nEpoch [1]\naccuracy (validation): tensor(0.8645, device='cuda:0')\nEpoch [2]\naccuracy (validation): tensor(0.9949, device='cuda:0')\nEpoch [3]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [4]\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [5]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [6]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [7]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [8]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [9]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [10]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [11]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [12]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [13]\naccuracy (validation): tensor(0.9974, device='cuda:0')\nEpoch [14]\naccuracy (validation): tensor(0.9974, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n\n\n\"\"\" if os.path.exists('submission.csv'):\n    csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\nelse:\n\"\"\"\nif os.path.exists('submission.csv'):\n    os.remove('submission.csv')\n    \nfile = open('submission.csv', 'w', newline='')\ncsv_writer = csv.writer(file)\ncsv_writer.writerow([\"filename\", \"label\"])\n\n\ntask1_model.eval()\nwith torch.no_grad():\n    for image, filenames in test_dl:\n        image = image.to(device)\n\n        pred = task1_model(image)\n        pred = torch.argmax(pred, dim=1)\n\n        for i in range(len(filenames)):\n            csv_writer.writerow([filenames[i], str(pred[i].item())])\n\n        del image, pred\n        torch.cuda.empty_cache()\n    \nfile.close()\n\ndel task1_model, train_ds, train_dl, val_ds, val_dl, test_ds, test_dl\ntorch.cuda.empty_cache()\ntime.sleep(10)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:51:08.434001Z","iopub.execute_input":"2022-12-13T03:51:08.434664Z","iopub.status.idle":"2022-12-13T03:51:58.582561Z","shell.execute_reply.started":"2022-12-13T03:51:08.434618Z","shell.execute_reply":"2022-12-13T03:51:58.581334Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## TASK2","metadata":{}},{"cell_type":"code","source":"class Task2Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        #img = cv2.resize(img, (32, 32))\n        #img = np.mean(img, axis=2)\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            #new_label = np.array([code[label[0]], code[label[1]]])\n            #new_label = [0] * 72\n            new_label = np.zeros(shape=72)\n            new_label[code[label[0]]] = 1\n            new_label[code[label[1]]+36] = 1\n            #new_label += np.array([0, 36])\n            new_label = torch.LongTensor(new_label)\n            return img, new_label\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:51:58.587739Z","iopub.execute_input":"2022-12-13T03:51:58.588062Z","iopub.status.idle":"2022-12-13T03:51:58.602781Z","shell.execute_reply.started":"2022-12-13T03:51:58.588036Z","shell.execute_reply":"2022-12-13T03:51:58.601867Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_ds = Task2Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task2Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:51:58.607825Z","iopub.execute_input":"2022-12-13T03:51:58.610347Z","iopub.status.idle":"2022-12-13T03:51:58.621532Z","shell.execute_reply.started":"2022-12-13T03:51:58.610311Z","shell.execute_reply":"2022-12-13T03:51:58.620556Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Task2Model(nn.Module):\n    def __init__(self):\n        super(Task2Model, self).__init__()\n\n        self.resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n        self.fc1 = nn.Linear(in_features=1000, out_features=36, bias=True)\n        self.fc2 = nn.Linear(in_features=1000, out_features=36, bias=True)\n\n    def forward(self, x):\n        x = self.resnet(x)\n        output_1 = self.fc1(x)\n        output_2 = self.fc2(x)\n\n        return output_1, output_2\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:51:58.626155Z","iopub.execute_input":"2022-12-13T03:51:58.628932Z","iopub.status.idle":"2022-12-13T03:51:58.638441Z","shell.execute_reply.started":"2022-12-13T03:51:58.628897Z","shell.execute_reply":"2022-12-13T03:51:58.637352Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"task2_model = resnet18(pretrained=True)\ntask2_model.fc = nn.Linear(in_features=512, out_features=72, bias=True)\ntask2_model = task2_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:51:58.642849Z","iopub.execute_input":"2022-12-13T03:51:58.645777Z","iopub.status.idle":"2022-12-13T03:51:58.930405Z","shell.execute_reply.started":"2022-12-13T03:51:58.645741Z","shell.execute_reply":"2022-12-13T03:51:58.929400Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#task2_model = Task2Model().to(device)\n#weights = ResNet18_Weights.IMAGENET1K_V1\n#preprocess = weights.transforms()\n\n#task2_model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n#task2_model = densenet201(weights=DenseNet201_Weights.IMAGENET1K_V1)\n#task2_model.fc = nn.Linear(in_features=512, out_features=72, bias=True)\n\noptimizer = torch.optim.Adam(task2_model.parameters(), lr=1e-3)\n#loss_fn = nn.CrossEntropyLoss()\nloss_fn = nn.MultiLabelSoftMarginLoss()\n\n\nfor epoch in range(15):\n    print(f\"Epoch [{epoch}]\")\n    task2_model.train()\n\n    train_loss = 0.0\n    for image, label in train_dl:\n\n        image = image.to(device)\n        #label_1, label_2 = label[:, 0], label[:, 1]\n        label = label.to(device)\n        #label_1, label_2 = label_1.to(device, dtype=torch.long), label_2.to(device, dtype=torch.long)\n        \n        #pred_1, pred_2 = task2_model(image)\n        #image_transformed = preprocess(image)\n\n        pred = task2_model(image)\n        loss = loss_fn(pred, label)\n        #loss_1, loss_2 = loss_fn(pred_1, label_1), loss_fn(pred_2, label_2)\n        \n        #loss = loss_1 + loss_2\n        train_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        torch.cuda.empty_cache()\n    \n    #print(len(train_dl))\n    train_loss /= len(train_dl)\n    print(\"train loss: {}\".format(train_loss))\n\n    sample_count = 0\n    correct_count = 0\n    task2_model.eval()\n    val_loss = 0\n    \n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n            #label_1, label_2 = label[:, 0], label[:, 1]\n            #label_1, label_2 = label_1.to(device, dtype=torch.long), label_2.to(device, dtype=torch.long)\n\n            #pred_1, pred_2 = task2_model(image)\n            #loss_1, loss_2 = loss_fn(pred_1, label_1), loss_fn(pred_2, label_2)\n\n            #loss = loss_1 + loss_2\n            #val_loss += loss\n            #print(\"loss: {}\".format(loss))\n\n            #image_transformed = preprocess(image)\n\n            pred = task2_model(image)\n            loss = loss_fn(pred, label)\n            #print(\"pred: \", pred)\n            #print(\"label: \", label)\n            val_loss += loss\n            #pred_1, pred_2 = torch.argmax(pred_1, dim=1), torch.argmax(pred_2, dim=1)\n            #pred = torch.stack([pred_1, pred_2], dim=1)\n\n            sample_count += len(image)\n            #correct = torch.sum(pred == label, dim=1)\n            #print(correct)\n            correct_count += calc_acc(pred, label)\n            #correct_count += torch.sum(correct == 2)\n\n            del image, label, pred\n            torch.cuda.empty_cache()\n\n        val_loss /= len(val_dl)\n        print(\"val loss: {}\".format(val_loss))\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:51:58.931805Z","iopub.execute_input":"2022-12-13T03:51:58.932204Z","iopub.status.idle":"2022-12-13T03:54:09.630903Z","shell.execute_reply.started":"2022-12-13T03:51:58.932170Z","shell.execute_reply":"2022-12-13T03:54:09.628979Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch [0]\ntrain loss: 0.19868609309196472\nval loss: 0.12428098171949387\naccuracy (validation): tensor(0.0101, device='cuda:0')\nEpoch [1]\ntrain loss: 0.07200135290622711\nval loss: 0.05738452821969986\naccuracy (validation): tensor(0.5445, device='cuda:0')\nEpoch [2]\ntrain loss: 0.029997337609529495\nval loss: 0.021313676610589027\naccuracy (validation): tensor(0.9534, device='cuda:0')\nEpoch [3]\ntrain loss: 0.01326115895062685\nval loss: 0.014311007224023342\naccuracy (validation): tensor(0.9838, device='cuda:0')\nEpoch [4]\ntrain loss: 0.007500041276216507\nval loss: 0.008731787092983723\naccuracy (validation): tensor(0.9919, device='cuda:0')\nEpoch [5]\ntrain loss: 0.005140959285199642\nval loss: 0.00661154929548502\naccuracy (validation): tensor(0.9939, device='cuda:0')\nEpoch [6]\ntrain loss: 0.0038404117804020643\nval loss: 0.0049431356601417065\naccuracy (validation): tensor(0.9939, device='cuda:0')\nEpoch [7]\ntrain loss: 0.0030675772577524185\nval loss: 0.004416735842823982\naccuracy (validation): tensor(0.9960, device='cuda:0')\nEpoch [8]\ntrain loss: 0.0025937031023204327\nval loss: 0.0035646825563162565\naccuracy (validation): tensor(1., device='cuda:0')\nEpoch [9]\ntrain loss: 0.002148767001926899\nval loss: 0.0033817205112427473\naccuracy (validation): tensor(0.9960, device='cuda:0')\nEpoch [10]\ntrain loss: 0.001918370253406465\nval loss: 0.002842410234734416\naccuracy (validation): tensor(0.9960, device='cuda:0')\nEpoch [11]\ntrain loss: 0.0016859043389558792\nval loss: 0.0026314721908420324\naccuracy (validation): tensor(0.9939, device='cuda:0')\nEpoch [12]\ntrain loss: 0.001452488824725151\nval loss: 0.0022411905229091644\naccuracy (validation): tensor(0.9960, device='cuda:0')\nEpoch [13]\ntrain loss: 0.0013212804915383458\nval loss: 0.00198158691637218\naccuracy (validation): tensor(0.9980, device='cuda:0')\nEpoch [14]\ntrain loss: 0.0011776232859119773\nval loss: 0.0019384485203772783\naccuracy (validation): tensor(0.9960, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = Task2Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n\nfile = open('submission.csv', 'a', newline='')\ncsv_writer = csv.writer(file)\n\ntask2_model.eval()\nwith torch.no_grad():\n    for image, filenames in test_dl:\n        image = image.to(device)\n\n        pred = task2_model(image)\n        pred = pred.view(-1, 2, 36)\n        pred = torch.argmax(pred, dim=2)\n\n        for i in range(len(filenames)):\n            csv_writer.writerow([filenames[i], rev_code[pred[i][0].item()] + rev_code[pred[i][1].item()]])\n\n        del image, pred\n        torch.cuda.empty_cache()\n    \nfile.close()\ndel task2_model, train_ds, train_dl, val_ds, val_dl, test_ds, test_dl\ntorch.cuda.empty_cache()\ntime.sleep(10)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:54:09.633301Z","iopub.execute_input":"2022-12-13T03:54:09.633789Z","iopub.status.idle":"2022-12-13T03:54:34.696756Z","shell.execute_reply.started":"2022-12-13T03:54:09.633746Z","shell.execute_reply":"2022-12-13T03:54:34.695771Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## TASK3","metadata":{}},{"cell_type":"code","source":"class Task3Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        #img = cv2.resize(img, (32, 32))\n        #img = np.mean(img, axis=2)\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            new_label = np.zeros(shape=144)\n            for i in range(4):\n                new_label[code[label[i]]+i*36] = 1\n            new_label = torch.LongTensor(new_label)\n            return img, new_label\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:54:34.698139Z","iopub.execute_input":"2022-12-13T03:54:34.699023Z","iopub.status.idle":"2022-12-13T03:54:34.708847Z","shell.execute_reply.started":"2022-12-13T03:54:34.698986Z","shell.execute_reply":"2022-12-13T03:54:34.707905Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_ds = Task3Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task3Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:54:34.711304Z","iopub.execute_input":"2022-12-13T03:54:34.711969Z","iopub.status.idle":"2022-12-13T03:54:34.726268Z","shell.execute_reply.started":"2022-12-13T03:54:34.711932Z","shell.execute_reply":"2022-12-13T03:54:34.725321Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class Task3Model(nn.Module):\n    def __init__(self):\n        super(Task3Model, self).__init__()\n\n        self.resnet = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n        self.fc1 = nn.Linear(in_features=1000, out_features=36, bias=True)\n        self.fc2 = nn.Linear(in_features=1000, out_features=36, bias=True)\n        self.fc3 = nn.Linear(in_features=1000, out_features=36, bias=True)\n        self.fc4 = nn.Linear(in_features=1000, out_features=36, bias=True)\n\n    def forward(self, x):\n        x = self.resnet(x)\n        output_1 = self.fc1(x)\n        output_2 = self.fc2(x)\n        output_3 = self.fc3(x)\n        output_4 = self.fc4(x)\n\n        return output_1, output_2, output_3, output_4","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:54:34.727768Z","iopub.execute_input":"2022-12-13T03:54:34.728235Z","iopub.status.idle":"2022-12-13T03:54:34.737730Z","shell.execute_reply.started":"2022-12-13T03:54:34.728202Z","shell.execute_reply":"2022-12-13T03:54:34.736839Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"task3_model = resnet18(pretrained=True)\ntask3_model.fc = nn.Linear(in_features=512, out_features=144, bias=True)\ntask3_model = task3_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:54:34.740797Z","iopub.execute_input":"2022-12-13T03:54:34.741054Z","iopub.status.idle":"2022-12-13T03:54:34.972240Z","shell.execute_reply.started":"2022-12-13T03:54:34.741031Z","shell.execute_reply":"2022-12-13T03:54:34.971187Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#task3_model = Task3Model().to(device)\n\noptimizer = torch.optim.Adam(task3_model.parameters(), lr=1e-3)\nloss_fn = nn.MultiLabelSoftMarginLoss()\n#loss_fn = nn.CrossEntropyLoss()\n\n\nfor epoch in range(30):\n    print(f\"Epoch [{epoch}]\")\n    task3_model.train()\n\n    train_loss = 0.0\n    for image, label in train_dl:\n\n        image = image.to(device)\n        #label_1, label_2 = label[:, 0], label[:, 1]\n        label = label.to(device)\n        #label_1, label_2 = label_1.to(device, dtype=torch.long), label_2.to(device, dtype=torch.long)\n        \n        #pred_1, pred_2 = task2_model(image)\n        #image_transformed = preprocess(image)\n\n        pred = task3_model(image)\n        loss = loss_fn(pred, label)\n        #loss_1, loss_2 = loss_fn(pred_1, label_1), loss_fn(pred_2, label_2)\n        \n        #loss = loss_1 + loss_2\n        train_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        torch.cuda.empty_cache()\n    \n    #print(len(train_dl))\n    train_loss /= len(train_dl)\n    print(\"train loss: {}\".format(train_loss))\n\n    sample_count = 0\n    correct_count = 0\n    task3_model.eval()\n    val_loss = 0\n    \n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n            #label_1, label_2 = label[:, 0], label[:, 1]\n            #label_1, label_2 = label_1.to(device, dtype=torch.long), label_2.to(device, dtype=torch.long)\n\n            #pred_1, pred_2 = task2_model(image)\n            #loss_1, loss_2 = loss_fn(pred_1, label_1), loss_fn(pred_2, label_2)\n\n            #loss = loss_1 + loss_2\n            #val_loss += loss\n            #print(\"loss: {}\".format(loss))\n\n            #image_transformed = preprocess(image)\n\n            pred = task3_model(image)\n            loss = loss_fn(pred, label)\n            #print(\"pred: \", pred)\n            #print(\"label: \", label)\n            val_loss += loss\n            #pred_1, pred_2 = torch.argmax(pred_1, dim=1), torch.argmax(pred_2, dim=1)\n            #pred = torch.stack([pred_1, pred_2], dim=1)\n\n            sample_count += len(image)\n            #correct = torch.sum(pred == label, dim=1)\n            #print(correct)\n            correct_count += calc_acc(pred, label)\n            #correct_count += torch.sum(correct == 2)\n\n            del image, label, pred\n            torch.cuda.empty_cache()\n\n        val_loss /= len(val_dl)\n        print(\"val loss: {}\".format(val_loss))\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:54:34.973710Z","iopub.execute_input":"2022-12-13T03:54:34.974062Z","iopub.status.idle":"2022-12-13T04:01:18.159613Z","shell.execute_reply.started":"2022-12-13T03:54:34.974025Z","shell.execute_reply":"2022-12-13T04:01:18.158375Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch [0]\ntrain loss: 0.19341254234313965\nval loss: 0.16344736516475677\naccuracy (validation): tensor(0., device='cuda:0')\nEpoch [1]\ntrain loss: 0.11939717829227448\nval loss: 0.11782940477132797\naccuracy (validation): tensor(0., device='cuda:0')\nEpoch [2]\ntrain loss: 0.10955627262592316\nval loss: 0.11009625345468521\naccuracy (validation): tensor(0.0016, device='cuda:0')\nEpoch [3]\ntrain loss: 0.08882983773946762\nval loss: 0.0843895748257637\naccuracy (validation): tensor(0.0225, device='cuda:0')\nEpoch [4]\ntrain loss: 0.06447996944189072\nval loss: 0.05849217250943184\naccuracy (validation): tensor(0.1562, device='cuda:0')\nEpoch [5]\ntrain loss: 0.04463999345898628\nval loss: 0.04615025594830513\naccuracy (validation): tensor(0.4348, device='cuda:0')\nEpoch [6]\ntrain loss: 0.030389750376343727\nval loss: 0.033639609813690186\naccuracy (validation): tensor(0.7295, device='cuda:0')\nEpoch [7]\ntrain loss: 0.020533449947834015\nval loss: 0.025174720212817192\naccuracy (validation): tensor(0.8438, device='cuda:0')\nEpoch [8]\ntrain loss: 0.014344396069645882\nval loss: 0.02028137817978859\naccuracy (validation): tensor(0.9340, device='cuda:0')\nEpoch [9]\ntrain loss: 0.010751866735517979\nval loss: 0.015527528710663319\naccuracy (validation): tensor(0.9356, device='cuda:0')\nEpoch [10]\ntrain loss: 0.008342096582055092\nval loss: 0.01337545644491911\naccuracy (validation): tensor(0.9581, device='cuda:0')\nEpoch [11]\ntrain loss: 0.0066306074149906635\nval loss: 0.011779339984059334\naccuracy (validation): tensor(0.9517, device='cuda:0')\nEpoch [12]\ntrain loss: 0.005440507549792528\nval loss: 0.010227116756141186\naccuracy (validation): tensor(0.9694, device='cuda:0')\nEpoch [13]\ntrain loss: 0.0044362363405525684\nval loss: 0.00891144759953022\naccuracy (validation): tensor(0.9775, device='cuda:0')\nEpoch [14]\ntrain loss: 0.0036429266911000013\nval loss: 0.008180706761777401\naccuracy (validation): tensor(0.9710, device='cuda:0')\nEpoch [15]\ntrain loss: 0.003197042504325509\nval loss: 0.007559473626315594\naccuracy (validation): tensor(0.9710, device='cuda:0')\nEpoch [16]\ntrain loss: 0.0028613724280148745\nval loss: 0.007146131247282028\naccuracy (validation): tensor(0.9807, device='cuda:0')\nEpoch [17]\ntrain loss: 0.0024990513920783997\nval loss: 0.006341435480862856\naccuracy (validation): tensor(0.9807, device='cuda:0')\nEpoch [18]\ntrain loss: 0.0021612169221043587\nval loss: 0.00572125893086195\naccuracy (validation): tensor(0.9775, device='cuda:0')\nEpoch [19]\ntrain loss: 0.001907243044115603\nval loss: 0.005657287314534187\naccuracy (validation): tensor(0.9775, device='cuda:0')\nEpoch [20]\ntrain loss: 0.0017094494542106986\nval loss: 0.00507771922275424\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [21]\ntrain loss: 0.0015391558408737183\nval loss: 0.004938495345413685\naccuracy (validation): tensor(0.9807, device='cuda:0')\nEpoch [22]\ntrain loss: 0.0013823198387399316\nval loss: 0.004867891781032085\naccuracy (validation): tensor(0.9742, device='cuda:0')\nEpoch [23]\ntrain loss: 0.0012872188817709684\nval loss: 0.004472142551094294\naccuracy (validation): tensor(0.9839, device='cuda:0')\nEpoch [24]\ntrain loss: 0.0011695533758029342\nval loss: 0.0043839928694069386\naccuracy (validation): tensor(0.9791, device='cuda:0')\nEpoch [25]\ntrain loss: 0.0011026454158127308\nval loss: 0.004327724222093821\naccuracy (validation): tensor(0.9775, device='cuda:0')\nEpoch [26]\ntrain loss: 0.0010062330402433872\nval loss: 0.0039757536724209785\naccuracy (validation): tensor(0.9807, device='cuda:0')\nEpoch [27]\ntrain loss: 0.0009335852228105068\nval loss: 0.0037586751859635115\naccuracy (validation): tensor(0.9823, device='cuda:0')\nEpoch [28]\ntrain loss: 0.0008534403750672936\nval loss: 0.0036588015500456095\naccuracy (validation): tensor(0.9807, device='cuda:0')\nEpoch [29]\ntrain loss: 0.0008223511977121234\nval loss: 0.003676387947052717\naccuracy (validation): tensor(0.9775, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_ds = Task3Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n\nfile = open('submission.csv', 'a', newline='')\ncsv_writer = csv.writer(file)\n\ntask3_model.eval()\n\nwith torch.no_grad():\n    for image, filenames in test_dl:\n        image = image.to(device)\n\n        pred = task3_model(image)\n        pred = pred.view(-1, 4, 36)\n        pred = torch.argmax(pred, dim=2)\n\n        for i in range(len(filenames)):\n            csv_writer.writerow([filenames[i], rev_code[pred[i][0].item()] + rev_code[pred[i][1].item()] + \\\n                                                rev_code[pred[i][2].item()] + rev_code[pred[i][3].item()]])    \n\n        del image, pred\n        torch.cuda.empty_cache()\n    \nfile.close()    \ndel task3_model, train_ds, train_dl, val_ds, val_dl, test_ds, test_dl\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T04:01:18.161036Z","iopub.execute_input":"2022-12-13T04:01:18.162622Z","iopub.status.idle":"2022-12-13T04:01:27.986460Z","shell.execute_reply.started":"2022-12-13T04:01:18.162574Z","shell.execute_reply":"2022-12-13T04:01:27.985500Z"},"trusted":true},"execution_count":23,"outputs":[]}]}