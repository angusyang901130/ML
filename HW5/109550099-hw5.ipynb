{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"9c6da53ade2302c5c2549050a755f7271f56c4989f0bdbb18e4ce6e64f091b09"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames[:3]:\n#         print(os.path.join(dirname, filename))\n#     if len(filenames) > 3:\n#         print(\"...\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-13T11:51:50.094164Z","iopub.status.busy":"2022-12-13T11:51:50.093677Z","iopub.status.idle":"2022-12-13T11:51:50.123838Z","shell.execute_reply":"2022-12-13T11:51:50.122730Z","shell.execute_reply.started":"2022-12-13T11:51:50.094062Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import csv\nimport numpy as np\nimport random\nimport time\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision.io import read_image\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:51:50.126915Z","iopub.status.busy":"2022-12-13T11:51:50.126028Z","iopub.status.idle":"2022-12-13T11:51:52.142643Z","shell.execute_reply":"2022-12-13T11:51:52.141575Z","shell.execute_reply.started":"2022-12-13T11:51:50.126877Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"/kaggle/input/captcha-hacker/train\"\n#TEST_PATH = \"/kaggle/input/captcha-hacker/test\"\n#TRAIN_PATH = \"./train\"\n#TEST_PATH = \"./test\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# try device = \"cuda\" \n# and change your settings/accelerator to GPU if you want it to run faster","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:51:52.148409Z","iopub.status.busy":"2022-12-13T11:51:52.147873Z","iopub.status.idle":"2022-12-13T11:51:52.214671Z","shell.execute_reply":"2022-12-13T11:51:52.213547Z","shell.execute_reply.started":"2022-12-13T11:51:52.148359Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"code = {}\nrev_code = {}\n\nnum = 0\nfor i in range(10):\n    code[str(i)] = num\n    rev_code[num] = str(i)\n    num += 1\n\nfor i in range(ord('a'), ord('z') + 1):\n    code[chr(i)]  = num\n    rev_code[num] = chr(i)\n    num += 1\n\n#print(code)   \n\n","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:51:52.218610Z","iopub.status.busy":"2022-12-13T11:51:52.217254Z","iopub.status.idle":"2022-12-13T11:51:52.228797Z","shell.execute_reply":"2022-12-13T11:51:52.227766Z","shell.execute_reply.started":"2022-12-13T11:51:52.218572Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def calc_acc(output, label):  \n    digits = int(output.shape[1] / 36)\n    output, label = output.view((-1, digits , 36)), label.view((-1, digits, 36))\n    output = nn.functional.softmax(output, dim=2)\n    \n    output, label = torch.argmax(output, dim=2), torch.argmax(label, dim=2)\n    \n    correct = torch.sum(output == label, dim=1)\n    correct = torch.sum(correct == digits, dim=0)\n\n    return correct","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:51:52.231426Z","iopub.status.busy":"2022-12-13T11:51:52.230001Z","iopub.status.idle":"2022-12-13T11:51:52.240717Z","shell.execute_reply":"2022-12-13T11:51:52.239558Z","shell.execute_reply.started":"2022-12-13T11:51:52.231389Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data = []\nval_data = []\n\nwith open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n    for row in csv.reader(csvfile, delimiter=','):\n        if random.random() < 0.85:\n            train_data.append(row)\n        else:\n            val_data.append(row)\n","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:51:52.244405Z","iopub.status.busy":"2022-12-13T11:51:52.244050Z","iopub.status.idle":"2022-12-13T11:51:52.295494Z","shell.execute_reply":"2022-12-13T11:51:52.294579Z","shell.execute_reply.started":"2022-12-13T11:51:52.244372Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## TASK1","metadata":{}},{"cell_type":"code","source":"class Task1Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        \n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            return img, int(label)\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:51:52.302054Z","iopub.status.busy":"2022-12-13T11:51:52.300030Z","iopub.status.idle":"2022-12-13T11:51:52.313361Z","shell.execute_reply":"2022-12-13T11:51:52.312450Z","shell.execute_reply.started":"2022-12-13T11:51:52.302025Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_ds = Task1Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task1Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:51:52.320113Z","iopub.status.busy":"2022-12-13T11:51:52.317805Z","iopub.status.idle":"2022-12-13T11:51:52.329471Z","shell.execute_reply":"2022-12-13T11:51:52.328366Z","shell.execute_reply.started":"2022-12-13T11:51:52.320076Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"task1_model = resnet18(pretrained=True)\ntask1_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\ntask1_model = task1_model.to(device)\n#print(model)","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:51:52.333586Z","iopub.status.busy":"2022-12-13T11:51:52.333257Z","iopub.status.idle":"2022-12-13T11:52:03.959143Z","shell.execute_reply":"2022-12-13T11:52:03.958214Z","shell.execute_reply.started":"2022-12-13T11:51:52.333540Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed2d87f7b70042098ccc785ad36a6020","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","source":"\noptimizer = torch.optim.Adam(task1_model.parameters(), lr=3e-4)\nloss_fn = nn.CrossEntropyLoss()\n\n\nfor epoch in range(15):\n    print(f\"Epoch [{epoch}]\")\n    task1_model.train()\n    for image, label in train_dl:\n        image = image.to(device)\n        label = label.to(device)\n        \n        pred = task1_model(image)\n        loss = loss_fn(pred, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        #torch.cuda.empty_cache()\n        \n    sample_count = 0\n    correct_count = 0\n    task1_model.eval()\n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n\n            pred = task1_model(image)\n            loss = loss_fn(pred, label)\n\n            pred = torch.argmax(pred, dim=1)\n\n            sample_count += len(image)\n            correct_count += (label == pred).sum()\n\n            del image, label, pred\n            #torch.cuda.empty_cache()\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)\n\ntorch.save(task1_model.state_dict(), \"task1_model.pt\")","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:52:03.963301Z","iopub.status.busy":"2022-12-13T11:52:03.962963Z","iopub.status.idle":"2022-12-13T11:53:50.971370Z","shell.execute_reply":"2022-12-13T11:53:50.970231Z","shell.execute_reply.started":"2022-12-13T11:52:03.963274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TASK2","metadata":{}},{"cell_type":"code","source":"class Task2Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        \n        transform = transforms.Compose([\n            transforms.Resize(size=224),\n            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            #new_label = np.array([code[label[0]], code[label[1]]])\n            #new_label = [0] * 72\n            new_label = np.zeros(shape=72)\n            new_label[code[label[0]]] = 1\n            new_label[code[label[1]]+36] = 1\n            #new_label += np.array([0, 36])\n            new_label = torch.LongTensor(new_label)\n            return img, new_label\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:54:42.358183Z","iopub.status.busy":"2022-12-13T11:54:42.354980Z","iopub.status.idle":"2022-12-13T11:54:42.372118Z","shell.execute_reply":"2022-12-13T11:54:42.370850Z","shell.execute_reply.started":"2022-12-13T11:54:42.358140Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_ds = Task2Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task2Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:54:42.374823Z","iopub.status.busy":"2022-12-13T11:54:42.373751Z","iopub.status.idle":"2022-12-13T11:54:42.392475Z","shell.execute_reply":"2022-12-13T11:54:42.391296Z","shell.execute_reply.started":"2022-12-13T11:54:42.374784Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"task2_model = resnet18(pretrained=True)\ntask2_model.fc = nn.Linear(in_features=512, out_features=72, bias=True)\ntask2_model = task2_model.to(device)","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:54:42.395095Z","iopub.status.busy":"2022-12-13T11:54:42.394602Z","iopub.status.idle":"2022-12-13T11:54:42.743707Z","shell.execute_reply":"2022-12-13T11:54:42.742724Z","shell.execute_reply.started":"2022-12-13T11:54:42.395057Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(task2_model.parameters(), lr=1e-3)\nloss_fn = nn.MultiLabelSoftMarginLoss()\n\n\nfor epoch in range(15):\n    print(f\"Epoch [{epoch}]\")\n    task2_model.train()\n\n    train_loss = 0.0\n    for image, label in train_dl:\n\n        image = image.to(device)\n        label = label.to(device)\n\n        pred = task2_model(image)\n        loss = loss_fn(pred, label)\n        \n        train_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        #torch.cuda.empty_cache()\n    \n    train_loss /= len(train_dl)\n    print(\"train loss: {}\".format(train_loss))\n\n    sample_count = 0\n    correct_count = 0\n    task2_model.eval()\n    val_loss = 0\n    \n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n\n            pred = task2_model(image)\n            loss = loss_fn(pred, label)\n            val_loss += loss\n\n            sample_count += len(image)\n            correct_count += calc_acc(pred, label)\n\n            del image, label, pred\n            #torch.cuda.empty_cache()\n\n        val_loss /= len(val_dl)\n        print(\"val loss: {}\".format(val_loss))\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)\n\ntorch.save(task2_model.state_dict(), \"task2_model.pt\")","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:54:42.746127Z","iopub.status.busy":"2022-12-13T11:54:42.745420Z","iopub.status.idle":"2022-12-13T11:56:43.849201Z","shell.execute_reply":"2022-12-13T11:56:43.847288Z","shell.execute_reply.started":"2022-12-13T11:54:42.746088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TASK3","metadata":{}},{"cell_type":"code","source":"class Task3Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = read_image(f\"{self.root}/{filename}\")\n        img = torch.as_tensor(img, dtype=torch.float32)\n        \n        transform = transforms.Compose([\n            transforms.Resize(size=(384, 288)),\n            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n        img = transform(img)\n        if self.return_filename:\n            return img, filename\n        else:\n            new_label = np.zeros(shape=144)\n            for i in range(4):\n                new_label[code[label[i]]+i*36] = 1\n            new_label = torch.LongTensor(new_label)\n            return img, new_label\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:57:03.454027Z","iopub.status.busy":"2022-12-13T11:57:03.453647Z","iopub.status.idle":"2022-12-13T11:57:03.464591Z","shell.execute_reply":"2022-12-13T11:57:03.462536Z","shell.execute_reply.started":"2022-12-13T11:57:03.453989Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_ds = Task3Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n\nval_ds = Task3Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:57:03.466561Z","iopub.status.busy":"2022-12-13T11:57:03.465995Z","iopub.status.idle":"2022-12-13T11:57:03.478123Z","shell.execute_reply":"2022-12-13T11:57:03.477148Z","shell.execute_reply.started":"2022-12-13T11:57:03.466503Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"task3_model = resnet18(pretrained=True)\ntask3_model.fc = nn.Linear(in_features=512, out_features=144, bias=True)\ntask3_model = task3_model.to(device)","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:57:03.480227Z","iopub.status.busy":"2022-12-13T11:57:03.479551Z","iopub.status.idle":"2022-12-13T11:57:03.709123Z","shell.execute_reply":"2022-12-13T11:57:03.708062Z","shell.execute_reply.started":"2022-12-13T11:57:03.480176Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(task3_model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.85)\nloss_fn = nn.MultiLabelSoftMarginLoss()\n\n\nfor epoch in range(60):\n    print(f\"Epoch [{epoch}]\")\n    task3_model.train()\n\n    train_loss = 0.0\n    for image, label in train_dl:\n\n        image = image.to(device)\n        label = label.to(device)\n\n        pred = task3_model(image)\n        loss = loss_fn(pred, label)\n        \n        train_loss += loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        del image, label, pred\n        #torch.cuda.empty_cache()\n    \n    scheduler.step()\n    train_loss /= len(train_dl)\n    print(\"train loss: {}\".format(train_loss))\n\n    sample_count = 0\n    correct_count = 0\n    task3_model.eval()\n    val_loss = 0\n    \n    with torch.no_grad():\n        for image, label in val_dl:\n            image = image.to(device)\n            label = label.to(device)\n\n            pred = task3_model(image)\n            loss = loss_fn(pred, label)\n            val_loss += loss\n\n            sample_count += len(image)\n            correct_count += calc_acc(pred, label)\n\n            del image, label, pred\n            #torch.cuda.empty_cache()\n\n        val_loss /= len(val_dl)\n        print(\"val loss: {}\".format(val_loss))\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)\n\ntorch.save(task3_model.state_dict(), \"task3_model.pt\")","metadata":{"execution":{"iopub.execute_input":"2022-12-13T11:57:03.711239Z","iopub.status.busy":"2022-12-13T11:57:03.710896Z","iopub.status.idle":"2022-12-13T12:24:54.343537Z","shell.execute_reply":"2022-12-13T12:24:54.342266Z","shell.execute_reply.started":"2022-12-13T11:57:03.711204Z"},"trusted":true},"execution_count":null,"outputs":[]}]}