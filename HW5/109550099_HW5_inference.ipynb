{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0MjJgRnAr6k",
        "outputId": "ca56768e-5237-4016-aa87-3f80b3a8a124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO5BpeP5AttY",
        "outputId": "65754972-23e7-4cbd-ac3c-259deb394b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas==1.3.5 in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3.5) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3.5) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3.5) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.5) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm==4.64.0 in /usr/local/lib/python3.8/dist-packages (4.64.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas==1.3.5\n",
        "!pip install tqdm==4.64.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9hYxvLXtAlA0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "odMiUz0mAlA3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Self defined encoding of characters\n",
        "'''\n",
        "\n",
        "code = {}\n",
        "rev_code = {}\n",
        "\n",
        "num = 0\n",
        "for i in range(10):\n",
        "    code[str(i)] = num\n",
        "    rev_code[num] = str(i)\n",
        "    num += 1\n",
        "\n",
        "for i in range(ord('a'), ord('z') + 1):\n",
        "    code[chr(i)]  = num\n",
        "    rev_code[num] = chr(i)\n",
        "    num += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jMYLOL5BAlA3"
      },
      "outputs": [],
      "source": [
        "class Task1Dataset(Dataset):\n",
        "    def __init__(self, data, root, return_filename=False):\n",
        "        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n",
        "        self.return_filename = return_filename\n",
        "        self.root = root\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.data[index]\n",
        "        img = read_image(f\"{self.root}/{filename}\")\n",
        "        img = torch.as_tensor(img, dtype=torch.float32)\n",
        "        \n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(size=288),\n",
        "            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        img = transform(img)\n",
        "        if self.return_filename:\n",
        "            return img, filename\n",
        "        else:\n",
        "            return img, int(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mabdaRtnAlA4"
      },
      "outputs": [],
      "source": [
        "class Task2Dataset(Dataset):\n",
        "    def __init__(self, data, root, return_filename=False):\n",
        "        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n",
        "        self.return_filename = return_filename\n",
        "        self.root = root\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.data[index]\n",
        "        img = read_image(f\"{self.root}/{filename}\")\n",
        "        img = torch.as_tensor(img, dtype=torch.float32)\n",
        "        \n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(size=288),\n",
        "            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        img = transform(img)\n",
        "        if self.return_filename:\n",
        "            return img, filename\n",
        "        else:\n",
        "            #new_label = np.array([code[label[0]], code[label[1]]])\n",
        "            #new_label = [0] * 72\n",
        "            new_label = np.zeros(shape=72)\n",
        "            new_label[code[label[0]]] = 1\n",
        "            new_label[code[label[1]]+36] = 1\n",
        "            #new_label += np.array([0, 36])\n",
        "            new_label = torch.LongTensor(new_label)\n",
        "            return img, new_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6UqG-1nuAlA4"
      },
      "outputs": [],
      "source": [
        "class Task3Dataset(Dataset):\n",
        "    def __init__(self, data, root, return_filename=False):\n",
        "        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n",
        "        self.return_filename = return_filename\n",
        "        self.root = root\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.data[index]\n",
        "        img = read_image(f\"{self.root}/{filename}\")\n",
        "        img = torch.as_tensor(img, dtype=torch.float32)\n",
        "        \n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(size=(384, 288)),\n",
        "            transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        img = transform(img)\n",
        "        if self.return_filename:\n",
        "            return img, filename\n",
        "        else:\n",
        "            new_label = np.zeros(shape=144)\n",
        "            for i in range(4):\n",
        "                new_label[code[label[i]]+i*36] = 1\n",
        "            new_label = torch.LongTensor(new_label)\n",
        "            return img, new_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XTZewfLVAlA5"
      },
      "outputs": [],
      "source": [
        "TEST_PATH = \"/content/drive/MyDrive/kaggle/input/captcha-hacker/test\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krBdygPNAlA5",
        "outputId": "32f07f3f-71d1-49da-c019-ec547ef39dc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = []\n",
        "with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n",
        "    for row in csv.reader(csvfile, delimiter=','):\n",
        "        test_data.append(row)\n",
        "\n",
        "file = open('submission.csv', 'w', newline='')\n",
        "csv_writer = csv.writer(file)\n",
        "csv_writer.writerow([\"filename\", \"label\"])\n",
        "\n",
        "test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n",
        "\n",
        "task1_model = resnet18()\n",
        "task1_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "task1_model.load_state_dict(torch.load(\"/content/drive/MyDrive/kaggle/task1_model.pt\"))\n",
        "task1_model.to(device, dtype=torch.float32)\n",
        "\n",
        "task1_model.eval()\n",
        "with torch.no_grad():\n",
        "    for image, filenames in tqdm(test_dl):\n",
        "        image = image.to(device)\n",
        "\n",
        "        pred = task1_model(image)\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "\n",
        "        for i in range(len(filenames)):\n",
        "            csv_writer.writerow([filenames[i], str(pred[i].item())])\n",
        "\n",
        "        del image, pred\n",
        "\n",
        "test_ds = Task2Dataset(test_data, root=TEST_PATH, return_filename=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n",
        "\n",
        "task2_model = resnet18()\n",
        "task2_model.fc = nn.Linear(in_features=512, out_features=72, bias=True)\n",
        "task2_model.load_state_dict(torch.load(\"/content/drive/MyDrive/kaggle/task2_model.pt\"))\n",
        "task2_model.to(device, dtype=torch.float32)\n",
        "\n",
        "task2_model.eval()\n",
        "with torch.no_grad():\n",
        "    for image, filenames in tqdm(test_dl):\n",
        "        image = image.to(device)\n",
        "\n",
        "        pred = task2_model(image)\n",
        "        pred = pred.view(-1, 2, 36)\n",
        "        pred = torch.argmax(pred, dim=2)\n",
        "\n",
        "        for i in range(len(filenames)):\n",
        "            csv_writer.writerow([filenames[i], rev_code[pred[i][0].item()] + rev_code[pred[i][1].item()]])\n",
        "\n",
        "        del image, pred\n",
        "\n",
        "test_ds = Task3Dataset(test_data, root=TEST_PATH, return_filename=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=100, drop_last=False, shuffle=False)\n",
        "\n",
        "task3_model = resnet18()\n",
        "task3_model.fc = nn.Linear(in_features=512, out_features=144, bias=True)\n",
        "task3_model.load_state_dict(torch.load(\"/content/drive/MyDrive/kaggle/task3_model.pt\"))\n",
        "task3_model.to(device, dtype=torch.float32)\n",
        "\n",
        "task3_model.eval()\n",
        "with torch.no_grad():\n",
        "    for image, filenames in tqdm(test_dl):\n",
        "        image = image.to(device)\n",
        "\n",
        "        pred = task3_model(image)\n",
        "        pred = pred.view(-1, 4, 36)\n",
        "        pred = torch.argmax(pred, dim=2)\n",
        "\n",
        "        for i in range(len(filenames)):\n",
        "            csv_writer.writerow([filenames[i], rev_code[pred[i][0].item()] + rev_code[pred[i][1].item()] + \\\n",
        "                                                rev_code[pred[i][2].item()] + rev_code[pred[i][3].item()]])    \n",
        "\n",
        "        del image, pred\n",
        "        \n",
        "file.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9c6da53ade2302c5c2549050a755f7271f56c4989f0bdbb18e4ce6e64f091b09"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
